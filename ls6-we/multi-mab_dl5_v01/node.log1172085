Resetting modules to system default. Resetting $MODULEPATH back to system default. All extra directories will be removed from $MODULEPATH.
BEGIN INSIDE ENV.SH

Currently Loaded Modules:
  1) cmake/3.24.2   6) impi/19.0.9          11) openmm/7.7.0_a
  2) pmix/3.2.3     7) cuda/11.3       (g)  12) swig/4.1.1_b
  3) xalt/2.10.32   8) conda/4.12.0_a       13) boost/1.72.0_a
  4) TACC           9) envwestpa/1.0_b      14) amber/22_a
  5) intel/19.1.1  10) fftw/3.3.10_a        15) westpa/22.06_b

  Where:
   g:  built for GPU

 

/work/09416/dty7/ls6/module_build_we_amber/modules/envwestpa/1.0_b/bin/python
END   INSIDE ENV.SH
starting WEST client processes on: 
c316-010.ls6.tacc.utexas.edu
current directory is /home1/09416/dty7/scratch/eg5/ls6-we/multi-mab_dl5_v01
environment is: 
CUDA_VISIBLE_DEVICES =  0,1,2
-- INFO     [westpa.rc] -- loading system driver 'westpa.core.systems.WESTSystem'
-- INFO     [westpa.rc] -- Loading system options from configuration file
Updating system with the options from the configuration file
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_ndim
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_len
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_dtype
-- INFO     [westpa.rc] -- Overwriting system option: bin_mapper
-- INFO     [westpa.rc] -- Overwriting system option: bin_target_counts
-- INFO     [westpa.core.we_driver] -- Adjust counts to exactly match target_counts: True
-- INFO     [westpa.core.we_driver] -- Obey abolute weight thresholds: True
-- INFO     [westpa.core.we_driver] -- Split threshold: 2.0
-- INFO     [westpa.core.we_driver] -- Merge cutoff: 1.0
-- INFO     [westpa.core.we_driver] -- Largest allowed weight: 0.1
-- INFO     [westpa.core.we_driver] -- Smallest allowed_weight: 1e-129
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.edaed408-ca8b-47d9-bd63-df54d7b64833] -- This is ZMQWorker on c308-003.ls6.tacc.utexas.edu at PID 2249047
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.20e7d141-ed18-433c-b025-bf66dc8dc537] -- This is ZMQWorker on c308-003.ls6.tacc.utexas.edu at PID 2249047
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.cd7a3adf-79b6-4e21-b80f-30e4bcabaaf5] -- This is ZMQExecutor on c308-003.ls6.tacc.utexas.edu at PID 2249056
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.9c6ca881-7356-4fff-8f01-1c6df9c0e27b] -- This is ZMQExecutor on c308-003.ls6.tacc.utexas.edu at PID 2249049
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.deaae59e-d920-493a-a830-ac79def6c00b] -- This is ZMQWorker on c316-003.ls6.tacc.utexas.edu at PID 3680316
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.b0efb272-8607-4783-83af-062262172cbe] -- This is ZMQExecutor on c316-003.ls6.tacc.utexas.edu at PID 3680332
-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process 2249049
-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process 2249056
-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process 2249063
Shutting down.  Hopefully this was on purpose?
