Resetting modules to system default. Resetting $MODULEPATH back to system default. All extra directories will be removed from $MODULEPATH.
BEGIN INSIDE ENV.SH

Currently Loaded Modules:
  1) cmake/3.24.2   6) impi/19.0.9          11) openmm/7.7.0_a
  2) pmix/3.2.3     7) cuda/11.3       (g)  12) swig/4.1.1_b
  3) xalt/2.10.32   8) conda/4.12.0_a       13) boost/1.72.0_a
  4) TACC           9) envwestpa/1.0_b      14) amber/22_a
  5) intel/19.1.1  10) fftw/3.3.10_a        15) westpa/22.06_b

  Where:
   g:  built for GPU

 

/work/09416/dty7/ls6/module_build_we_amber/modules/envwestpa/1.0_b/bin/python
END   INSIDE ENV.SH
starting WEST client processes on: 
c316-001.ls6.tacc.utexas.edu
current directory is /home1/09416/dty7/scratch/eg5/ls6-we/multi-mab_dl5_v01
environment is: 
CUDA_VISIBLE_DEVICES =  0,1,2
-- INFO     [westpa.rc] -- loading system driver 'westpa.core.systems.WESTSystem'
-- INFO     [westpa.rc] -- Loading system options from configuration file
Updating system with the options from the configuration file
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_ndim
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_len
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_dtype
-- INFO     [westpa.rc] -- Overwriting system option: bin_mapper
-- INFO     [westpa.rc] -- Overwriting system option: bin_target_counts
-- INFO     [westpa.core.we_driver] -- Adjust counts to exactly match target_counts: True
-- INFO     [westpa.core.we_driver] -- Obey abolute weight thresholds: True
-- INFO     [westpa.core.we_driver] -- Split threshold: 2.0
-- INFO     [westpa.core.we_driver] -- Merge cutoff: 1.0
-- INFO     [westpa.core.we_driver] -- Largest allowed weight: 0.1
-- INFO     [westpa.core.we_driver] -- Smallest allowed_weight: 1e-129
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.5cedf921-b7a0-4898-8c2f-84fbdb9ce4a9] -- This is ZMQWorker on c316-001.ls6.tacc.utexas.edu at PID 913689
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.22f62283-0989-4137-bb6f-df0ede4da323] -- This is ZMQWorker on c316-001.ls6.tacc.utexas.edu at PID 913689
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.86cd3b6f-ede2-40df-83a3-36bca73e5d27] -- This is ZMQExecutor on c316-001.ls6.tacc.utexas.edu at PID 913694
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.73abe16f-e711-45b7-b404-24b9e8a07bf0] -- This is ZMQExecutor on c316-001.ls6.tacc.utexas.edu at PID 913691
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.708ad7f2-9513-4f2e-956b-e2fdf4fbc7ba] -- This is ZMQWorker on c316-001.ls6.tacc.utexas.edu at PID 913689
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.1879d63f-3f37-446f-877a-d44cb699332d] -- This is ZMQExecutor on c316-001.ls6.tacc.utexas.edu at PID 913705
-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process 351363
-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process 351370
-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to worker process 351377
Shutting down.  Hopefully this was on purpose?
