Resetting modules to system default. Resetting $MODULEPATH back to system dResetting modules to system default. Resetting $MODULEPATH back to system default. A
Currently Loaded Modules:
  1) cmake/3.24.2   6) impi/19.0.9          11) 
Currently Loaded Modules:
  1) cmake/3.24.2   6) impi/19.0.9          11) openmm/7.7.0_a
  2) pmix/3.2.3     7) cuda/11.3       (g)  12) swig/4.1.1_b
  3) xalt/2.10.32   8) conda/4.12.0_a       13) boost/1.72.0_a
  4) TACC           9) envwestpa/1.0_b      14) amber/22_a
  5) intel/19.1.1  10) fftw/3.3.10_a        15) westpa/22.06_b

  Where:
   g:  built for GPU

 

/work/09416/dty7/ls6/module_build_we_amber/modules/envwestpa/1.0_b/bin/python
END   INSIDE ENV.SH
starting WEST client processes on: 
c317-006.ls6.tacc.utexas.edu
current directory is /home1/09416/dty7/scratch/e-- INFO     [westpa.rc] -- loading system driver 'westpa.core.systems.WESTS-- INFO     [westpa.rc] -- loading system driver 'westpa.core.systems.WESTSystem'
-- INFO     [westpa.rc] -- Loading system options from configuration file
Updating system with the options from the configuration file
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_ndim
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_len
-- INFO     [westpa.rc] -- Overwriting system option: pcoord_dtype
-- INFO     [westpa.rc] -- Overwriting system option: bin_mapper
-- INFO     [westpa.rc] -- Overwriting system option: bin_target_counts
-- INFO     [westpa.core.we_driver] -- Adjust counts to exactly match target_counts: True
-- INFO     [westpa.core.we_driver] -- Obey abolute weight thresholds: True
-- INFO     [westpa.core.we_driver] -- Split threshold: 2.0
-- INFO     [westpa.core.we_driver] -- Merge cutoff: 1.0
-- INFO     [westpa.core.we_driver] -- Largest allowed weight: 0.1
-- INFO     [westpa.core.we_driver] -- Smallest allowed_weight: 1e-129
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.7d99b387-d221-474b-ba56-4d81d5fd54de] -- This is ZMQWorker on c317-006.ls6.tacc.utexas.edu at PID 315725
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.5e5afad5-ff03-404c-a560-7a849f0a9534] -- This is ZMQWorker on c317-006.ls6.tacc.utexas.edu at PID 315725
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.2d7119f4-76a4-4cec-970b-edf3808fd09d] -- This is ZMQExecutor on c317-006.ls6.tacc.utexas.edu at PID 315728
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.fec470ea-d5d6-4f65-ab84-36d7459adea7] -- This is ZMQExecutor on c317-006.ls6.tacc.utexas.edu at PID 315731
-- INFO     [westpa.work_managers.zeromq.core.ZMQWorker.670319ce-8085-4bcd-8fcf-662c50b1b2e8] -- This is ZMQWorker on c317-006.ls6.tacc.utexas.edu at PID 315725
-- INFO     [westpa.work_managers.zeromq.core.ZMQExecutor.fbee2516-20db-4e9a-8169-754318556598] -- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to -- WARNING  [westpa.wor-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL to-- WARNING  [westpa.work-- WARNING  [westpa.work_managers.zeromq.core] -- sending SIGKILL t-- WARNING  [westpa.work_Shutting down.  Hopefully this was on purpose?
Connection to c315-003 closed by remote host.
is was on purpose?
Connection to c317-006 closed by remote host.
